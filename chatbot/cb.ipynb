{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import nltk\n",
    "from keras.models import Sequential\n",
    "from keras.layers.recurrent import LSTM, SimpleRNN\n",
    "from keras.layers import Activation, TimeDistributed, Dense, RepeatVector, recurrent, Embedding\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_lines(file_path, separator, name_idx, content_idx, start_line = 0, limit = 10000):\n",
    "    ln = 1\n",
    "    line_added = 0\n",
    "    prev_name = None\n",
    "    sentences = []\n",
    "    for line in open(file_path, 'r', encoding=\"utf-8\"):\n",
    "\n",
    "        if ln >= start_line + limit:\n",
    "            if line_added % 2 == 0:\n",
    "                break\n",
    "            else:\n",
    "                limit += 1\n",
    "        elif ln < start_line:\n",
    "            ln += 1\n",
    "            continue\n",
    "        ln += 1\n",
    "        items = line.split(separator)\n",
    "        name = items[name_idx].lower()\n",
    "        content = items[content_idx].lower().replace('?', '').replace('!', '').replace( '.', '').replace( ',', '').replace( '-', '')\n",
    "        words = content.split()\n",
    "        if prev_name != name:\n",
    "            sentences.append(words)\n",
    "            line_added +=1\n",
    "        else:\n",
    "            #print(prev_name, \"spoke again\")\n",
    "            sentences[-1].extend(words )\n",
    "        prev_name = name\n",
    "    #print(len(sentences))\n",
    "    if len(sentences) % 2 != 0:\n",
    "        sentences.pop();\n",
    "    return sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def exclude_long_sentences(source_path, output_path, word_limit = 20, line_separator = '\\n', convo_separator = \"\\n\\n\\n\\n\"):\n",
    "    wfile = open(output_path, \"w\")\n",
    "    rfile = open(source_path, \"r\")\n",
    "    content = rfile.read()\n",
    "    convos = content.split(convo_separator)\n",
    "    for convo in convos:\n",
    "        sentences_to_write = []\n",
    "        sentences = convo.split(line_separator)\n",
    "        under_limit = True\n",
    "        for sen in sentences:\n",
    "            words = sen.split()\n",
    "            if len(words) > word_limit:\n",
    "                under_limit = False\n",
    "                break\n",
    "            sentences_to_write.append(sen)\n",
    "        if under_limit:\n",
    "            sl = len(sentences_to_write)\n",
    "            for i in range(sl):\n",
    "                wfile.write(sentences_to_write[i])\n",
    "                if i == sl - 1:\n",
    "                    wfile.write(convo_separator)\n",
    "                else:\n",
    "                    wfile.write(line_separator)\n",
    "    wfile.close()\n",
    "    rfile.close()\n",
    "def read_sentences(file_path,line_separator = '\\n', convo_separator = \"\\n\\n\\n\\n\"):\n",
    "    sentences = []\n",
    "    rfile = open(file_path, \"r\")\n",
    "    content = rfile.read()\n",
    "    convos = content.split(convo_separator)\n",
    "    for convo in convos:\n",
    "        sens = convo.split(line_separator)\n",
    "        for sen in sens:\n",
    "            words = sen.lower().replace('?', '').replace('!', '').replace( '.', '').replace( ',', '').replace( '-', '').replace(';', '').split()\n",
    "            sentences.append(words)\n",
    "    return sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#flatten_sentences = [word for sentence in sentences for word in sentence ]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def build_vocab_dict(sentences, padding_char, unknown_char):\n",
    "    word_freq = nltk.FreqDist(np.hstack(sentences))\n",
    "    word_freq.pop(padding_char, None)\n",
    "    word_freq.pop(unknown_char, None)\n",
    "    vocab = word_freq.most_common(VOCAB_SIZE - 2)\n",
    "\n",
    "    vocab.insert(0, (padding_char,1))\n",
    "    vocab.append( (unknown_char,1))\n",
    "    \n",
    "    vocab_dict = {pair[0]: id for id, pair in enumerate(vocab)}\n",
    "    \n",
    "    idx_dict = {idx:word for word, idx in vocab_dict.items()}\n",
    "    print(idx_dict)\n",
    "    return vocab_dict, idx_dict\n",
    "\n",
    "\n",
    "#print(vocab_dict, idx_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_vocab(vocab_dict):\n",
    "    f = open(\"vocab_dict.json\", 'w') \n",
    "    f.write(json.dumps(vocab_dict)) \n",
    "    f.close() \n",
    "def load_vocab():\n",
    "    f = open(\"vocab_dict.json\", 'r') \n",
    "    vocab_dict = json.loads(f.read() )\n",
    "    f.close() \n",
    "    idx_dict = idx_dict = {idx:word for word, idx in vocab_dict.items()}\n",
    "    return vocab_dict, idx_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentence_to_vec(sentences, vocab_dict, unknown_char, sentence_length):\n",
    "    l = len(sentences)\n",
    "    vec = []\n",
    "    unk_idx = vocab_dict[unknown_char]\n",
    "\n",
    "    for sen in sentences:\n",
    "        vec.append( [vocab_dict[x] if x in vocab_dict else unk_idx for x in sen ][:20])\n",
    "\n",
    "    padded = pad_sequences(vec, maxlen=sentence_length, dtype='int32')\n",
    "    return padded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_one_hot(vec, sentence_length, vocab_length):\n",
    "    print((len(vec), sentence_length, vocab_length))\n",
    "    res = np.zeros((len(vec), sentence_length, vocab_length))\n",
    "    for i, sen in enumerate(vec):\n",
    "        for j, num in enumerate(sen):\n",
    "            res[i, j, num] = 1\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vectorize_sentence(sentences, vocab_dict, vocab_size, sentence_size):\n",
    "\n",
    "    x_sentences = [sentences[i] for i in range(len(sentences)) if i % 2 == 0]\n",
    "    y_sentences = [sentences[i] for i in range(len(sentences)) if i % 2 == 1]\n",
    "    \n",
    "    if len(x_sentences) > len(y_sentences):\n",
    "        x_sentences = x_sentences[:-1]\n",
    "    elif len(y_sentences) > len(x_sentences):\n",
    "        y_sentences = y_sentences[:-1]\n",
    "    #print(x_sentences,x_sentences)\n",
    "    x_vec = sentence_to_vec(x_sentences, vocab_dict, 'UNK', sentence_size)\n",
    "    y_vec = sentence_to_vec(y_sentences, vocab_dict, 'UNK', sentence_size)\n",
    "\n",
    "    y_vec = to_one_hot(y_vec, sentence_size, vocab_size)\n",
    "    return x_vec, y_vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(x_vocab_len, x_max_len, y_vocab_len, y_max_len, hidden_size, num_layers):\n",
    "    model = Sequential()\n",
    "\n",
    "    # Creating encoder network\n",
    "    model.add(Embedding(x_vocab_len, 1024, input_length=x_max_len, mask_zero=True))\n",
    "    model.add(LSTM(hidden_size))\n",
    "    model.add(RepeatVector(y_max_len))\n",
    "\n",
    "    # Creating decoder network\n",
    "    for _ in range(num_layers):\n",
    "        model.add(LSTM(hidden_size, return_sequences=True))\n",
    "    model.add(TimeDistributed(Dense(y_vocab_len)))\n",
    "    model.add(Activation('softmax'))\n",
    "    model.compile(loss='categorical_crossentropy',\n",
    "            optimizer='rmsprop',\n",
    "            metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nsentences = read_lines(\"movie_lines.txt\", \" +++$+++ \", 3, 4, 0, 1000)\\n\\nvocab_dict, idx_dict = build_vocab_dict(sentences, \\' \\', \\'UNK\\')\\n#save_vocab(vocab_dict)\\nvocab_dict, idx_dict = load_vocab()\\n#print(vocab_dict, idx_dict)\\n\\n#sentences=[\"hi\",\"i\\'m good\",\"hello\",\"hello\",\"hey\",\"hey there\", \\'shit\\',\\'i know right\\']\\n#sentences= sentences + sentences + sentences + sentences\\n#sentences= sentences + sentences + sentences + sentences\\n#sentences= sentences + sentences + sentences + sentences\\n\\n\\nx_sentences = [sentences[i] for i in range(len(sentences)) if i % 2 == 0]\\ny_sentences = [sentences[i] for i in range(len(sentences)) if i % 2 == 1]\\n\\nx_vec = sentence_to_vec(x_sentences, vocab_dict, \\'UNK\\', SENTENCE_LENGTH)\\ny_vec = sentence_to_vec(y_sentences, vocab_dict, \\'UNK\\', SENTENCE_LENGTH)\\ny_vec = to_one_hot(y_vec, SENTENCE_LENGTH, VOCAB_SIZE)\\n\\nprint(x_vec.shape, y_vec.shape)\\n\\nmodel = create_model(VOCAB_SIZE, SENTENCE_LENGTH, VOCAB_SIZE, SENTENCE_LENGTH, 1024, 3)\\n#model.summary()\\nmodel.load_weights(\"new_chatbot_model.h5\")\\n'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SENTENCE_LENGTH = 20\n",
    "VOCAB_SIZE = 10000\n",
    "\"\"\"\n",
    "sentences = read_lines(\"movie_lines.txt\", \" +++$+++ \", 3, 4, 0, 1000)\n",
    "\n",
    "vocab_dict, idx_dict = build_vocab_dict(sentences, ' ', 'UNK')\n",
    "#save_vocab(vocab_dict)\n",
    "vocab_dict, idx_dict = load_vocab()\n",
    "#print(vocab_dict, idx_dict)\n",
    "\n",
    "#sentences=[\"hi\",\"i'm good\",\"hello\",\"hello\",\"hey\",\"hey there\", 'shit','i know right']\n",
    "#sentences= sentences + sentences + sentences + sentences\n",
    "#sentences= sentences + sentences + sentences + sentences\n",
    "#sentences= sentences + sentences + sentences + sentences\n",
    "\n",
    "\n",
    "x_sentences = [sentences[i] for i in range(len(sentences)) if i % 2 == 0]\n",
    "y_sentences = [sentences[i] for i in range(len(sentences)) if i % 2 == 1]\n",
    "\n",
    "x_vec = sentence_to_vec(x_sentences, vocab_dict, 'UNK', SENTENCE_LENGTH)\n",
    "y_vec = sentence_to_vec(y_sentences, vocab_dict, 'UNK', SENTENCE_LENGTH)\n",
    "y_vec = to_one_hot(y_vec, SENTENCE_LENGTH, VOCAB_SIZE)\n",
    "\n",
    "print(x_vec.shape, y_vec.shape)\n",
    "\n",
    "model = create_model(VOCAB_SIZE, SENTENCE_LENGTH, VOCAB_SIZE, SENTENCE_LENGTH, 1024, 3)\n",
    "#model.summary()\n",
    "model.load_weights(\"new_chatbot_model.h5\")\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_cornell_movie_data(start_line, limit, vocab_dict):\n",
    "    sentences = read_lines(\"movie_lines.txt\", \" +++$+++ \", 3, 4, start_line, limit)\n",
    "    x_vec, y_vec = vectorize_sentence(sentences, vocab_dict, VOCAB_SIZE, SENTENCE_LENGTH)\n",
    "    return x_vec, y_vec\n",
    "\n",
    "def load_twitter_data(start_line, limit, vocab_dict):\n",
    "    sentences = read_sentences(\"ShortenTwitterAsciiCorpus.txt\")[:1000]\n",
    "    x_vec, y_vec = vectorize_sentence(sentences, vocab_dict, VOCAB_SIZE, SENTENCE_LENGTH)\n",
    "    return x_vec, y_vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = create_model(VOCAB_SIZE, SENTENCE_LENGTH, VOCAB_SIZE, SENTENCE_LENGTH, 1024, 3)\n",
    "#model.summary()\n",
    "model.load_weights(\"new_chatbot_model.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_dict, idx_dict = load_vocab()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting data: 0 1000\n",
      "(500, 20, 10000)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\models.py:981: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
      "  warnings.warn('The `nb_epoch` argument in `fit` '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "500/500 [==============================] - 37s 73ms/step - loss: 3.1660 - acc: 0.7146\n",
      "--------------------------------------------------------------------------\n",
      "Round: 0 Batch: 1\n",
      "--------------------------------------------------------------------------\n",
      "Getting data: 1000 1000\n",
      "(500, 20, 10000)\n",
      "Epoch 1/1\n",
      "500/500 [==============================] - 35s 70ms/step - loss: 3.3678 - acc: 0.6737\n",
      "--------------------------------------------------------------------------\n",
      "Round: 0 Batch: 2\n",
      "--------------------------------------------------------------------------\n",
      "Getting data: 2000 1000\n",
      "(500, 20, 10000)\n",
      "Epoch 1/1\n",
      "500/500 [==============================] - 36s 72ms/step - loss: 2.9621 - acc: 0.7214\n",
      "--------------------------------------------------------------------------\n",
      "Round: 0 Batch: 3\n",
      "--------------------------------------------------------------------------\n",
      "Getting data: 3000 1000\n",
      "(500, 20, 10000)\n",
      "Epoch 1/1\n",
      "500/500 [==============================] - 35s 70ms/step - loss: 2.6646 - acc: 0.7610\n",
      "--------------------------------------------------------------------------\n",
      "Round: 0 Batch: 4\n",
      "--------------------------------------------------------------------------\n",
      "Getting data: 4000 1000\n",
      "(500, 20, 10000)\n",
      "Epoch 1/1\n",
      "500/500 [==============================] - 35s 70ms/step - loss: 2.4681 - acc: 0.7875\n",
      "--------------------------------------------------------------------------\n",
      "Round: 0 Batch: 5\n",
      "--------------------------------------------------------------------------\n",
      "Getting data: 5000 1000\n",
      "(500, 20, 10000)\n",
      "Epoch 1/1\n",
      "500/500 [==============================] - 36s 72ms/step - loss: 2.3462 - acc: 0.8065\n",
      "--------------------------------------------------------------------------\n",
      "Round: 0 Batch: 6\n",
      "--------------------------------------------------------------------------\n",
      "Getting data: 6000 1000\n",
      "(500, 20, 10000)\n",
      "Epoch 1/1\n",
      "500/500 [==============================] - 37s 74ms/step - loss: 2.2541 - acc: 0.8200\n",
      "--------------------------------------------------------------------------\n",
      "Round: 0 Batch: 7\n",
      "--------------------------------------------------------------------------\n",
      "Getting data: 7000 1000\n",
      "(500, 20, 10000)\n",
      "Epoch 1/1\n",
      "500/500 [==============================] - 36s 72ms/step - loss: 2.1905 - acc: 0.8280\n",
      "--------------------------------------------------------------------------\n",
      "Round: 0 Batch: 8\n",
      "--------------------------------------------------------------------------\n",
      "Getting data: 8000 1000\n",
      "(500, 20, 10000)\n",
      "Epoch 1/1\n",
      "500/500 [==============================] - 35s 70ms/step - loss: 2.1258 - acc: 0.8356\n",
      "--------------------------------------------------------------------------\n",
      "Round: 0 Batch: 9\n",
      "--------------------------------------------------------------------------\n",
      "Getting data: 9000 1000\n",
      "(500, 20, 10000)\n",
      "Epoch 1/1\n",
      "500/500 [==============================] - 35s 70ms/step - loss: 2.0737 - acc: 0.8416\n",
      "--------------------------------------------------------------------------\n",
      "Round: 0 Batch: 10\n",
      "--------------------------------------------------------------------------\n",
      "Getting data: 10000 1000\n",
      "(500, 20, 10000)\n",
      "Epoch 1/1\n",
      "500/500 [==============================] - 36s 73ms/step - loss: 2.0396 - acc: 0.8453\n",
      "--------------------------------------------------------------------------\n",
      "Round: 0 Batch: 11\n",
      "--------------------------------------------------------------------------\n",
      "Getting data: 11000 1000\n",
      "(500, 20, 10000)\n",
      "Epoch 1/1\n",
      "500/500 [==============================] - 35s 69ms/step - loss: 2.0070 - acc: 0.8531\n",
      "--------------------------------------------------------------------------\n",
      "Round: 0 Batch: 12\n",
      "--------------------------------------------------------------------------\n",
      "Getting data: 12000 1000\n",
      "(500, 20, 10000)\n",
      "Epoch 1/1\n",
      "500/500 [==============================] - 35s 69ms/step - loss: 1.9751 - acc: 0.8553\n",
      "--------------------------------------------------------------------------\n",
      "Round: 0 Batch: 13\n",
      "--------------------------------------------------------------------------\n",
      "Getting data: 13000 1000\n",
      "(500, 20, 10000)\n",
      "Epoch 1/1\n",
      "500/500 [==============================] - 35s 70ms/step - loss: 1.9647 - acc: 0.8556\n",
      "--------------------------------------------------------------------------\n",
      "Round: 0 Batch: 14\n",
      "--------------------------------------------------------------------------\n",
      "Getting data: 14000 1000\n",
      "(500, 20, 10000)\n",
      "Epoch 1/1\n",
      "500/500 [==============================] - 35s 70ms/step - loss: 1.9549 - acc: 0.8564\n",
      "--------------------------------------------------------------------------\n",
      "Round: 0 Batch: 15\n",
      "--------------------------------------------------------------------------\n",
      "Getting data: 15000 1000\n",
      "(500, 20, 10000)\n",
      "Epoch 1/1\n",
      "500/500 [==============================] - 36s 71ms/step - loss: 1.9197 - acc: 0.8604\n",
      "--------------------------------------------------------------------------\n",
      "Round: 0 Batch: 16\n",
      "--------------------------------------------------------------------------\n",
      "Getting data: 16000 1000\n",
      "(500, 20, 10000)\n",
      "Epoch 1/1\n",
      "500/500 [==============================] - 35s 70ms/step - loss: 1.9086 - acc: 0.8612\n",
      "--------------------------------------------------------------------------\n",
      "Round: 0 Batch: 17\n",
      "--------------------------------------------------------------------------\n",
      "Getting data: 17000 1000\n",
      "(500, 20, 10000)\n",
      "Epoch 1/1\n",
      "500/500 [==============================] - 36s 71ms/step - loss: 1.8834 - acc: 0.8617\n",
      "--------------------------------------------------------------------------\n",
      "Round: 0 Batch: 18\n",
      "--------------------------------------------------------------------------\n",
      "Getting data: 18000 1000\n",
      "(500, 20, 10000)\n",
      "Epoch 1/1\n",
      "500/500 [==============================] - 39s 78ms/step - loss: 1.8719 - acc: 0.8619\n",
      "--------------------------------------------------------------------------\n",
      "Round: 0 Batch: 19\n",
      "--------------------------------------------------------------------------\n",
      "Getting data: 19000 1000\n",
      "(500, 20, 10000)\n",
      "Epoch 1/1\n",
      "500/500 [==============================] - 35s 70ms/step - loss: 1.8611 - acc: 0.8622\n",
      "--------------------------------------------------------------------------\n",
      "Round: 0 Batch: 20\n",
      "--------------------------------------------------------------------------\n",
      "Getting data: 20000 1000\n",
      "(500, 20, 10000)\n",
      "Epoch 1/1\n",
      "500/500 [==============================] - 36s 71ms/step - loss: 1.8589 - acc: 0.8630\n",
      "--------------------------------------------------------------------------\n",
      "Round: 0 Batch: 21\n",
      "--------------------------------------------------------------------------\n",
      "Getting data: 21000 1000\n",
      "(500, 20, 10000)\n",
      "Epoch 1/1\n",
      "500/500 [==============================] - 35s 70ms/step - loss: 1.8282 - acc: 0.8663\n",
      "--------------------------------------------------------------------------\n",
      "Round: 0 Batch: 22\n",
      "--------------------------------------------------------------------------\n",
      "Getting data: 22000 1000\n",
      "(500, 20, 10000)\n",
      "Epoch 1/1\n",
      "500/500 [==============================] - 37s 74ms/step - loss: 1.8177 - acc: 0.8668\n",
      "--------------------------------------------------------------------------\n",
      "Round: 0 Batch: 23\n",
      "--------------------------------------------------------------------------\n",
      "Getting data: 23000 1000\n",
      "(500, 20, 10000)\n",
      "Epoch 1/1\n",
      "500/500 [==============================] - 35s 70ms/step - loss: 1.8152 - acc: 0.8678\n",
      "--------------------------------------------------------------------------\n",
      "Round: 0 Batch: 24\n",
      "--------------------------------------------------------------------------\n",
      "Getting data: 24000 1000\n",
      "(500, 20, 10000)\n",
      "Epoch 1/1\n",
      "500/500 [==============================] - 35s 69ms/step - loss: 1.8075 - acc: 0.8667\n",
      "--------------------------------------------------------------------------\n",
      "Round: 0 Batch: 25\n",
      "--------------------------------------------------------------------------\n",
      "Getting data: 25000 1000\n",
      "(500, 20, 10000)\n",
      "Epoch 1/1\n",
      "500/500 [==============================] - 37s 74ms/step - loss: 1.7857 - acc: 0.8701\n",
      "--------------------------------------------------------------------------\n",
      "Round: 0 Batch: 26\n",
      "--------------------------------------------------------------------------\n",
      "Getting data: 26000 1000\n",
      "(500, 20, 10000)\n",
      "Epoch 1/1\n",
      "500/500 [==============================] - 36s 71ms/step - loss: 1.7661 - acc: 0.8720\n",
      "--------------------------------------------------------------------------\n",
      "Round: 0 Batch: 27\n",
      "--------------------------------------------------------------------------\n",
      "Getting data: 27000 1000\n",
      "(500, 20, 10000)\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "500/500 [==============================] - 36s 72ms/step - loss: 1.7520 - acc: 0.8720\n",
      "--------------------------------------------------------------------------\n",
      "Round: 0 Batch: 28\n",
      "--------------------------------------------------------------------------\n",
      "Getting data: 28000 1000\n",
      "(500, 20, 10000)\n",
      "Epoch 1/1\n",
      "500/500 [==============================] - 39s 77ms/step - loss: 1.7389 - acc: 0.8743\n",
      "--------------------------------------------------------------------------\n",
      "Round: 0 Batch: 29\n",
      "--------------------------------------------------------------------------\n",
      "Getting data: 29000 1000\n",
      "(500, 20, 10000)\n",
      "Epoch 1/1\n",
      "500/500 [==============================] - 40s 79ms/step - loss: 1.7307 - acc: 0.8755\n",
      "--------------------------------------------------------------------------\n",
      "Round: 0 Batch: 30\n",
      "--------------------------------------------------------------------------\n",
      "Getting data: 30000 1000\n",
      "(500, 20, 10000)\n",
      "Epoch 1/1\n",
      "500/500 [==============================] - 40s 80ms/step - loss: 1.7248 - acc: 0.8747\n",
      "--------------------------------------------------------------------------\n",
      "Round: 0 Batch: 31\n",
      "--------------------------------------------------------------------------\n",
      "Getting data: 31000 1000\n",
      "(500, 20, 10000)\n",
      "Epoch 1/1\n",
      "500/500 [==============================] - 38s 76ms/step - loss: 1.7140 - acc: 0.8775\n",
      "--------------------------------------------------------------------------\n",
      "Round: 0 Batch: 32\n",
      "--------------------------------------------------------------------------\n",
      "Getting data: 32000 1000\n",
      "(500, 20, 10000)\n",
      "Epoch 1/1\n",
      "500/500 [==============================] - 39s 77ms/step - loss: 1.7126 - acc: 0.8753\n",
      "--------------------------------------------------------------------------\n",
      "Round: 0 Batch: 33\n",
      "--------------------------------------------------------------------------\n",
      "Getting data: 33000 1000\n",
      "(500, 20, 10000)\n",
      "Epoch 1/1\n",
      "500/500 [==============================] - 40s 80ms/step - loss: 1.7116 - acc: 0.8764\n",
      "--------------------------------------------------------------------------\n",
      "Round: 0 Batch: 34\n",
      "--------------------------------------------------------------------------\n",
      "Getting data: 34000 1000\n",
      "(500, 20, 10000)\n",
      "Epoch 1/1\n",
      "500/500 [==============================] - 38s 77ms/step - loss: 1.6957 - acc: 0.8771\n",
      "--------------------------------------------------------------------------\n",
      "Round: 0 Batch: 35\n",
      "--------------------------------------------------------------------------\n",
      "Getting data: 35000 1000\n",
      "(500, 20, 10000)\n",
      "Epoch 1/1\n",
      "500/500 [==============================] - 36s 72ms/step - loss: 1.7044 - acc: 0.8743\n",
      "--------------------------------------------------------------------------\n",
      "Round: 0 Batch: 36\n",
      "--------------------------------------------------------------------------\n",
      "Getting data: 36000 1000\n",
      "(500, 20, 10000)\n",
      "Epoch 1/1\n",
      "500/500 [==============================] - 36s 73ms/step - loss: 1.6902 - acc: 0.8770\n",
      "--------------------------------------------------------------------------\n",
      "Round: 0 Batch: 37\n",
      "--------------------------------------------------------------------------\n",
      "Getting data: 37000 1000\n",
      "(500, 20, 10000)\n",
      "Epoch 1/1\n",
      "500/500 [==============================] - 36s 71ms/step - loss: 1.6812 - acc: 0.8761\n",
      "--------------------------------------------------------------------------\n",
      "Round: 0 Batch: 38\n",
      "--------------------------------------------------------------------------\n",
      "Getting data: 38000 1000\n",
      "(500, 20, 10000)\n",
      "Epoch 1/1\n",
      "500/500 [==============================] - 35s 71ms/step - loss: 1.6737 - acc: 0.8764\n",
      "--------------------------------------------------------------------------\n",
      "Round: 0 Batch: 39\n",
      "--------------------------------------------------------------------------\n",
      "Getting data: 39000 1000\n",
      "(500, 20, 10000)\n",
      "Epoch 1/1\n",
      "500/500 [==============================] - 37s 73ms/step - loss: 1.6787 - acc: 0.8753\n",
      "--------------------------------------------------------------------------\n",
      "Round: 0 Batch: 40\n",
      "--------------------------------------------------------------------------\n",
      "Getting data: 40000 1000\n",
      "(500, 20, 10000)\n",
      "Epoch 1/1\n",
      "500/500 [==============================] - 36s 72ms/step - loss: 1.6662 - acc: 0.8749\n",
      "--------------------------------------------------------------------------\n",
      "Round: 0 Batch: 41\n",
      "--------------------------------------------------------------------------\n",
      "Getting data: 41000 1000\n",
      "(500, 20, 10000)\n",
      "Epoch 1/1\n",
      "500/500 [==============================] - 36s 72ms/step - loss: 1.6703 - acc: 0.8732\n",
      "--------------------------------------------------------------------------\n",
      "Round: 0 Batch: 42\n",
      "--------------------------------------------------------------------------\n",
      "Getting data: 42000 1000\n",
      "(500, 20, 10000)\n",
      "Epoch 1/1\n",
      "500/500 [==============================] - 38s 77ms/step - loss: 1.6538 - acc: 0.8756\n",
      "--------------------------------------------------------------------------\n",
      "Round: 0 Batch: 43\n",
      "--------------------------------------------------------------------------\n",
      "Getting data: 43000 1000\n",
      "(500, 20, 10000)\n",
      "Epoch 1/1\n",
      "500/500 [==============================] - 39s 78ms/step - loss: 1.6327 - acc: 0.8800\n",
      "--------------------------------------------------------------------------\n",
      "Round: 0 Batch: 44\n",
      "--------------------------------------------------------------------------\n",
      "Getting data: 44000 1000\n",
      "(500, 20, 10000)\n",
      "Epoch 1/1\n",
      "500/500 [==============================] - 36s 72ms/step - loss: 1.6196 - acc: 0.8805\n",
      "--------------------------------------------------------------------------\n",
      "Round: 0 Batch: 45\n",
      "--------------------------------------------------------------------------\n",
      "Getting data: 45000 1000\n",
      "(500, 20, 10000)\n",
      "Epoch 1/1\n",
      "500/500 [==============================] - 36s 72ms/step - loss: 1.6101 - acc: 0.8815\n",
      "--------------------------------------------------------------------------\n",
      "Round: 0 Batch: 46\n",
      "--------------------------------------------------------------------------\n",
      "Getting data: 46000 1000\n",
      "(500, 20, 10000)\n",
      "Epoch 1/1\n",
      "500/500 [==============================] - 36s 72ms/step - loss: 1.6010 - acc: 0.8844\n",
      "--------------------------------------------------------------------------\n",
      "Round: 0 Batch: 47\n",
      "--------------------------------------------------------------------------\n",
      "Getting data: 47000 1000\n",
      "(500, 20, 10000)\n",
      "Epoch 1/1\n",
      "500/500 [==============================] - 35s 70ms/step - loss: 1.5944 - acc: 0.8855\n",
      "--------------------------------------------------------------------------\n",
      "Round: 0 Batch: 48\n",
      "--------------------------------------------------------------------------\n",
      "Getting data: 48000 1000\n",
      "(500, 20, 10000)\n",
      "Epoch 1/1\n",
      "500/500 [==============================] - 39s 77ms/step - loss: 1.5948 - acc: 0.8849\n",
      "--------------------------------------------------------------------------\n",
      "Round: 0 Batch: 49\n",
      "--------------------------------------------------------------------------\n",
      "Getting data: 49000 1000\n",
      "(500, 20, 10000)\n",
      "Epoch 1/1\n",
      "500/500 [==============================] - 36s 72ms/step - loss: 1.5996 - acc: 0.8842\n",
      "--------------------------------------------------------------------------\n",
      "Round: 0 Batch: 50\n",
      "--------------------------------------------------------------------------\n",
      "Getting data: 50000 1000\n",
      "(500, 20, 10000)\n",
      "Epoch 1/1\n",
      "500/500 [==============================] - 38s 75ms/step - loss: 1.6016 - acc: 0.8836\n",
      "--------------------------------------------------------------------------\n",
      "Round: 0 Batch: 51\n",
      "--------------------------------------------------------------------------\n",
      "Getting data: 51000 1000\n",
      "(500, 20, 10000)\n",
      "Epoch 1/1\n",
      "500/500 [==============================] - 37s 74ms/step - loss: 1.5903 - acc: 0.8827\n",
      "--------------------------------------------------------------------------\n",
      "Round: 0 Batch: 52\n",
      "--------------------------------------------------------------------------\n",
      "Getting data: 52000 1000\n",
      "(500, 20, 10000)\n",
      "Epoch 1/1\n",
      "500/500 [==============================] - 35s 71ms/step - loss: 1.5923 - acc: 0.8831\n",
      "--------------------------------------------------------------------------\n",
      "Round: 0 Batch: 53\n",
      "--------------------------------------------------------------------------\n",
      "Getting data: 53000 1000\n",
      "(500, 20, 10000)\n",
      "Epoch 1/1\n",
      "500/500 [==============================] - 36s 72ms/step - loss: 1.5877 - acc: 0.8819\n",
      "--------------------------------------------------------------------------\n",
      "Round: 0 Batch: 54\n",
      "--------------------------------------------------------------------------\n",
      "Getting data: 54000 1000\n",
      "(500, 20, 10000)\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "500/500 [==============================] - 36s 73ms/step - loss: 1.5905 - acc: 0.8829\n",
      "--------------------------------------------------------------------------\n",
      "Round: 0 Batch: 55\n",
      "--------------------------------------------------------------------------\n",
      "Getting data: 55000 1000\n",
      "(500, 20, 10000)\n",
      "Epoch 1/1\n",
      "500/500 [==============================] - 36s 72ms/step - loss: 1.5841 - acc: 0.8825\n",
      "--------------------------------------------------------------------------\n",
      "Round: 0 Batch: 56\n",
      "--------------------------------------------------------------------------\n",
      "Getting data: 56000 1000\n",
      "(500, 20, 10000)\n",
      "Epoch 1/1\n",
      "500/500 [==============================] - 36s 72ms/step - loss: 1.5872 - acc: 0.8829\n",
      "--------------------------------------------------------------------------\n",
      "Round: 0 Batch: 57\n",
      "--------------------------------------------------------------------------\n",
      "Getting data: 57000 1000\n",
      "(500, 20, 10000)\n",
      "Epoch 1/1\n",
      "500/500 [==============================] - 36s 73ms/step - loss: 1.5671 - acc: 0.8844\n",
      "--------------------------------------------------------------------------\n",
      "Round: 0 Batch: 58\n",
      "--------------------------------------------------------------------------\n",
      "Getting data: 58000 1000\n",
      "(500, 20, 10000)\n",
      "Epoch 1/1\n",
      "500/500 [==============================] - 37s 74ms/step - loss: 1.5622 - acc: 0.8853\n",
      "--------------------------------------------------------------------------\n",
      "Round: 0 Batch: 59\n",
      "--------------------------------------------------------------------------\n",
      "Getting data: 59000 1000\n",
      "(500, 20, 10000)\n",
      "Epoch 1/1\n",
      "500/500 [==============================] - 36s 71ms/step - loss: 1.5537 - acc: 0.8848\n",
      "--------------------------------------------------------------------------\n",
      "Round: 0 Batch: 60\n",
      "--------------------------------------------------------------------------\n",
      "Getting data: 60000 1000\n",
      "(500, 20, 10000)\n",
      "Epoch 1/1\n",
      "500/500 [==============================] - 36s 72ms/step - loss: 1.5551 - acc: 0.8841\n",
      "--------------------------------------------------------------------------\n",
      "Round: 0 Batch: 61\n",
      "--------------------------------------------------------------------------\n",
      "Getting data: 61000 1000\n",
      "(500, 20, 10000)\n",
      "Epoch 1/1\n",
      "500/500 [==============================] - 37s 73ms/step - loss: 1.5413 - acc: 0.8865\n",
      "--------------------------------------------------------------------------\n",
      "Round: 0 Batch: 62\n",
      "--------------------------------------------------------------------------\n",
      "Getting data: 62000 1000\n",
      "(500, 20, 10000)\n",
      "Epoch 1/1\n",
      "500/500 [==============================] - 37s 75ms/step - loss: 1.5341 - acc: 0.8880\n",
      "--------------------------------------------------------------------------\n",
      "Round: 0 Batch: 63\n",
      "--------------------------------------------------------------------------\n",
      "Getting data: 63000 1000\n",
      "(500, 20, 10000)\n",
      "Epoch 1/1\n",
      "500/500 [==============================] - 38s 77ms/step - loss: 1.5348 - acc: 0.8880\n",
      "--------------------------------------------------------------------------\n",
      "Round: 0 Batch: 64\n",
      "--------------------------------------------------------------------------\n",
      "Getting data: 64000 1000\n",
      "(500, 20, 10000)\n",
      "Epoch 1/1\n",
      "500/500 [==============================] - 39s 78ms/step - loss: 1.5338 - acc: 0.8859\n",
      "--------------------------------------------------------------------------\n",
      "Round: 0 Batch: 65\n",
      "--------------------------------------------------------------------------\n",
      "Getting data: 65000 1000\n",
      "(500, 20, 10000)\n",
      "Epoch 1/1\n",
      "500/500 [==============================] - 39s 79ms/step - loss: 1.5331 - acc: 0.8866\n",
      "--------------------------------------------------------------------------\n",
      "Round: 0 Batch: 66\n",
      "--------------------------------------------------------------------------\n",
      "Getting data: 66000 1000\n",
      "(500, 20, 10000)\n",
      "Epoch 1/1\n",
      "500/500 [==============================] - 40s 80ms/step - loss: 1.5253 - acc: 0.8867\n",
      "--------------------------------------------------------------------------\n",
      "Round: 0 Batch: 67\n",
      "--------------------------------------------------------------------------\n",
      "Getting data: 67000 1000\n",
      "(500, 20, 10000)\n",
      "Epoch 1/1\n",
      "500/500 [==============================] - 39s 78ms/step - loss: 1.5145 - acc: 0.8884\n",
      "--------------------------------------------------------------------------\n",
      "Round: 0 Batch: 68\n",
      "--------------------------------------------------------------------------\n",
      "Getting data: 68000 1000\n",
      "(500, 20, 10000)\n",
      "Epoch 1/1\n",
      "500/500 [==============================] - 36s 71ms/step - loss: 1.5073 - acc: 0.8878\n",
      "--------------------------------------------------------------------------\n",
      "Round: 0 Batch: 69\n",
      "--------------------------------------------------------------------------\n",
      "Getting data: 69000 1000\n",
      "(500, 20, 10000)\n",
      "Epoch 1/1\n",
      "500/500 [==============================] - 35s 70ms/step - loss: 1.5022 - acc: 0.8890\n",
      "--------------------------------------------------------------------------\n",
      "Round: 0 Batch: 70\n",
      "--------------------------------------------------------------------------\n",
      "Getting data: 70000 1000\n",
      "(500, 20, 10000)\n",
      "Epoch 1/1\n",
      "500/500 [==============================] - 35s 70ms/step - loss: 1.4967 - acc: 0.8900\n",
      "--------------------------------------------------------------------------\n",
      "Round: 0 Batch: 71\n",
      "--------------------------------------------------------------------------\n",
      "Getting data: 71000 1000\n",
      "(500, 20, 10000)\n",
      "Epoch 1/1\n",
      "500/500 [==============================] - 35s 70ms/step - loss: 1.5027 - acc: 0.8899\n",
      "--------------------------------------------------------------------------\n",
      "Round: 0 Batch: 72\n",
      "--------------------------------------------------------------------------\n",
      "Getting data: 72000 1000\n",
      "(500, 20, 10000)\n",
      "Epoch 1/1\n",
      "500/500 [==============================] - 35s 70ms/step - loss: 1.4945 - acc: 0.8904\n",
      "--------------------------------------------------------------------------\n",
      "Round: 0 Batch: 73\n",
      "--------------------------------------------------------------------------\n",
      "Getting data: 73000 1000\n",
      "(500, 20, 10000)\n",
      "Epoch 1/1\n",
      "500/500 [==============================] - 36s 71ms/step - loss: 1.4921 - acc: 0.8888\n",
      "--------------------------------------------------------------------------\n",
      "Round: 0 Batch: 74\n",
      "--------------------------------------------------------------------------\n",
      "Getting data: 74000 1000\n",
      "(500, 20, 10000)\n",
      "Epoch 1/1\n",
      "500/500 [==============================] - 35s 70ms/step - loss: 1.4960 - acc: 0.8886\n",
      "--------------------------------------------------------------------------\n",
      "Round: 0 Batch: 75\n",
      "--------------------------------------------------------------------------\n",
      "Getting data: 75000 1000\n",
      "(500, 20, 10000)\n",
      "Epoch 1/1\n",
      "500/500 [==============================] - 35s 70ms/step - loss: 1.4906 - acc: 0.8888\n",
      "--------------------------------------------------------------------------\n",
      "Round: 0 Batch: 76\n",
      "--------------------------------------------------------------------------\n",
      "Getting data: 76000 1000\n",
      "(500, 20, 10000)\n",
      "Epoch 1/1\n",
      "500/500 [==============================] - 35s 69ms/step - loss: 1.4926 - acc: 0.8857\n",
      "--------------------------------------------------------------------------\n",
      "Round: 0 Batch: 77\n",
      "--------------------------------------------------------------------------\n",
      "Getting data: 77000 1000\n",
      "(500, 20, 10000)\n",
      "Epoch 1/1\n",
      "500/500 [==============================] - 35s 70ms/step - loss: 1.4794 - acc: 0.8893\n",
      "--------------------------------------------------------------------------\n",
      "Round: 0 Batch: 78\n",
      "--------------------------------------------------------------------------\n",
      "Getting data: 78000 1000\n",
      "(500, 20, 10000)\n",
      "Epoch 1/1\n",
      "500/500 [==============================] - 35s 70ms/step - loss: 1.4686 - acc: 0.8905\n",
      "--------------------------------------------------------------------------\n",
      "Round: 0 Batch: 79\n",
      "--------------------------------------------------------------------------\n",
      "Getting data: 79000 1000\n",
      "(500, 20, 10000)\n",
      "Epoch 1/1\n",
      "500/500 [==============================] - 35s 69ms/step - loss: 1.4570 - acc: 0.8908\n",
      "--------------------------------------------------------------------------\n",
      "Round: 0 Batch: 80\n",
      "--------------------------------------------------------------------------\n",
      "Getting data: 80000 1000\n",
      "(500, 20, 10000)\n",
      "Epoch 1/1\n",
      "500/500 [==============================] - 36s 71ms/step - loss: 1.4511 - acc: 0.8941\n",
      "--------------------------------------------------------------------------\n",
      "Round: 0 Batch: 81\n",
      "--------------------------------------------------------------------------\n",
      "Getting data: 81000 1000\n",
      "(500, 20, 10000)\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "500/500 [==============================] - 35s 70ms/step - loss: 1.4448 - acc: 0.8933\n",
      "--------------------------------------------------------------------------\n",
      "Round: 0 Batch: 82\n",
      "--------------------------------------------------------------------------\n",
      "Getting data: 82000 1000\n",
      "(500, 20, 10000)\n",
      "Epoch 1/1\n",
      "500/500 [==============================] - 34s 68ms/step - loss: 1.4437 - acc: 0.8948\n",
      "--------------------------------------------------------------------------\n",
      "Round: 0 Batch: 83\n",
      "--------------------------------------------------------------------------\n",
      "Getting data: 83000 1000\n",
      "(500, 20, 10000)\n",
      "Epoch 1/1\n",
      "500/500 [==============================] - 34s 68ms/step - loss: 1.4384 - acc: 0.8944\n",
      "--------------------------------------------------------------------------\n",
      "Round: 0 Batch: 84\n",
      "--------------------------------------------------------------------------\n",
      "Getting data: 84000 1000\n",
      "(500, 20, 10000)\n",
      "Epoch 1/1\n",
      "500/500 [==============================] - 34s 69ms/step - loss: 1.4425 - acc: 0.8943\n",
      "--------------------------------------------------------------------------\n",
      "Round: 0 Batch: 85\n",
      "--------------------------------------------------------------------------\n",
      "Getting data: 85000 1000\n",
      "(500, 20, 10000)\n",
      "Epoch 1/1\n",
      "500/500 [==============================] - 34s 68ms/step - loss: 1.4356 - acc: 0.8950\n",
      "--------------------------------------------------------------------------\n",
      "Round: 0 Batch: 86\n",
      "--------------------------------------------------------------------------\n",
      "Getting data: 86000 1000\n",
      "(500, 20, 10000)\n",
      "Epoch 1/1\n",
      "500/500 [==============================] - 34s 68ms/step - loss: 1.4344 - acc: 0.8923\n",
      "--------------------------------------------------------------------------\n",
      "Round: 0 Batch: 87\n",
      "--------------------------------------------------------------------------\n",
      "Getting data: 87000 1000\n",
      "(500, 20, 10000)\n",
      "Epoch 1/1\n",
      "500/500 [==============================] - 34s 69ms/step - loss: 1.4318 - acc: 0.8955\n",
      "--------------------------------------------------------------------------\n",
      "Round: 0 Batch: 88\n",
      "--------------------------------------------------------------------------\n",
      "Getting data: 88000 1000\n",
      "(500, 20, 10000)\n",
      "Epoch 1/1\n",
      "500/500 [==============================] - 33s 67ms/step - loss: 1.4266 - acc: 0.8948\n",
      "--------------------------------------------------------------------------\n",
      "Round: 0 Batch: 89\n",
      "--------------------------------------------------------------------------\n",
      "Getting data: 89000 1000\n",
      "(500, 20, 10000)\n",
      "Epoch 1/1\n",
      "500/500 [==============================] - 37s 73ms/step - loss: 1.4369 - acc: 0.8930\n",
      "--------------------------------------------------------------------------\n",
      "Round: 0 Batch: 90\n",
      "--------------------------------------------------------------------------\n",
      "Getting data: 90000 1000\n",
      "(500, 20, 10000)\n",
      "Epoch 1/1\n",
      "500/500 [==============================] - 37s 73ms/step - loss: 1.4484 - acc: 0.8887\n",
      "--------------------------------------------------------------------------\n",
      "Round: 0 Batch: 91\n",
      "--------------------------------------------------------------------------\n",
      "Getting data: 91000 1000\n",
      "(500, 20, 10000)\n",
      "Epoch 1/1\n",
      "500/500 [==============================] - 36s 71ms/step - loss: 1.4494 - acc: 0.8870\n",
      "--------------------------------------------------------------------------\n",
      "Round: 0 Batch: 92\n",
      "--------------------------------------------------------------------------\n",
      "Getting data: 92000 1000\n",
      "(500, 20, 10000)\n",
      "Epoch 1/1\n",
      "500/500 [==============================] - 35s 70ms/step - loss: 1.4374 - acc: 0.8898\n",
      "--------------------------------------------------------------------------\n",
      "Round: 0 Batch: 93\n",
      "--------------------------------------------------------------------------\n",
      "Getting data: 93000 1000\n",
      "(500, 20, 10000)\n",
      "Epoch 1/1\n",
      "500/500 [==============================] - 35s 70ms/step - loss: 1.4170 - acc: 0.8929\n",
      "--------------------------------------------------------------------------\n",
      "Round: 0 Batch: 94\n",
      "--------------------------------------------------------------------------\n",
      "Getting data: 94000 1000\n",
      "(500, 20, 10000)\n",
      "Epoch 1/1\n",
      "500/500 [==============================] - 35s 69ms/step - loss: 1.4109 - acc: 0.8943\n",
      "--------------------------------------------------------------------------\n",
      "Round: 0 Batch: 95\n",
      "--------------------------------------------------------------------------\n",
      "Getting data: 95000 1000\n",
      "(500, 20, 10000)\n",
      "Epoch 1/1\n",
      "500/500 [==============================] - 35s 71ms/step - loss: 1.4037 - acc: 0.8969\n",
      "--------------------------------------------------------------------------\n",
      "Round: 0 Batch: 96\n",
      "--------------------------------------------------------------------------\n",
      "Getting data: 96000 1000\n",
      "(500, 20, 10000)\n",
      "Epoch 1/1\n",
      "500/500 [==============================] - 35s 70ms/step - loss: 1.3999 - acc: 0.8966\n",
      "--------------------------------------------------------------------------\n",
      "Round: 0 Batch: 97\n",
      "--------------------------------------------------------------------------\n",
      "Getting data: 97000 1000\n",
      "(500, 20, 10000)\n",
      "Epoch 1/1\n",
      "500/500 [==============================] - 37s 74ms/step - loss: 1.3974 - acc: 0.8950\n",
      "--------------------------------------------------------------------------\n",
      "Round: 0 Batch: 98\n",
      "--------------------------------------------------------------------------\n",
      "Getting data: 98000 1000\n",
      "(500, 20, 10000)\n",
      "Epoch 1/1\n",
      "500/500 [==============================] - 35s 71ms/step - loss: 1.3974 - acc: 0.8980\n",
      "--------------------------------------------------------------------------\n",
      "Round: 0 Batch: 99\n",
      "--------------------------------------------------------------------------\n",
      "Getting data: 99000 1000\n",
      "(500, 20, 10000)\n",
      "Epoch 1/1\n",
      "500/500 [==============================] - 35s 70ms/step - loss: 1.3965 - acc: 0.8973\n",
      "--------------------------------------------------------------------------\n",
      "Round: 0 Batch: 100\n",
      "--------------------------------------------------------------------------\n",
      "Getting data: 100000 1000\n",
      "(500, 20, 10000)\n",
      "Epoch 1/1\n",
      "500/500 [==============================] - 35s 70ms/step - loss: 1.3915 - acc: 0.8978\n",
      "--------------------------------------------------------------------------\n",
      "Round: 0 Batch: 101\n",
      "--------------------------------------------------------------------------\n",
      "Getting data: 101000 1000\n",
      "(500, 20, 10000)\n",
      "Epoch 1/1\n",
      "500/500 [==============================] - 37s 74ms/step - loss: 1.3935 - acc: 0.8973\n",
      "--------------------------------------------------------------------------\n",
      "Round: 0 Batch: 102\n",
      "--------------------------------------------------------------------------\n",
      "Getting data: 102000 1000\n",
      "(500, 20, 10000)\n",
      "Epoch 1/1\n",
      "500/500 [==============================] - 37s 75ms/step - loss: 1.3941 - acc: 0.8966\n",
      "--------------------------------------------------------------------------\n",
      "Round: 0 Batch: 103\n",
      "--------------------------------------------------------------------------\n",
      "Getting data: 103000 1000\n",
      "(500, 20, 10000)\n",
      "Epoch 1/1\n",
      "500/500 [==============================] - 35s 70ms/step - loss: 1.3894 - acc: 0.8963\n",
      "--------------------------------------------------------------------------\n",
      "Round: 0 Batch: 104\n",
      "--------------------------------------------------------------------------\n",
      "Getting data: 104000 1000\n",
      "(500, 20, 10000)\n",
      "Epoch 1/1\n",
      "500/500 [==============================] - 35s 71ms/step - loss: 1.3912 - acc: 0.8992\n",
      "--------------------------------------------------------------------------\n",
      "Round: 0 Batch: 105\n",
      "--------------------------------------------------------------------------\n",
      "Getting data: 105000 1000\n",
      "(500, 20, 10000)\n",
      "Epoch 1/1\n",
      "500/500 [==============================] - 35s 70ms/step - loss: 1.3950 - acc: 0.8962\n",
      "--------------------------------------------------------------------------\n",
      "Round: 0 Batch: 106\n",
      "--------------------------------------------------------------------------\n",
      "Getting data: 106000 1000\n",
      "(500, 20, 10000)\n",
      "Epoch 1/1\n",
      "500/500 [==============================] - 35s 70ms/step - loss: 1.3923 - acc: 0.8958\n",
      "--------------------------------------------------------------------------\n",
      "Round: 0 Batch: 107\n",
      "--------------------------------------------------------------------------\n",
      "Getting data: 107000 1000\n",
      "(500, 20, 10000)\n",
      "Epoch 1/1\n",
      "500/500 [==============================] - 35s 70ms/step - loss: 1.3992 - acc: 0.8945\n",
      "--------------------------------------------------------------------------\n",
      "Round: 0 Batch: 108\n",
      "--------------------------------------------------------------------------\n",
      "Getting data: 108000 1000\n",
      "(500, 20, 10000)\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "500/500 [==============================] - 35s 70ms/step - loss: 1.4025 - acc: 0.8934\n",
      "--------------------------------------------------------------------------\n",
      "Round: 0 Batch: 109\n",
      "--------------------------------------------------------------------------\n",
      "Getting data: 109000 1000\n",
      "(500, 20, 10000)\n",
      "Epoch 1/1\n",
      "500/500 [==============================] - 35s 70ms/step - loss: 1.3998 - acc: 0.8909\n",
      "--------------------------------------------------------------------------\n",
      "Round: 0 Batch: 110\n",
      "--------------------------------------------------------------------------\n",
      "Getting data: 110000 1000\n",
      "(500, 20, 10000)\n",
      "Epoch 1/1\n",
      "500/500 [==============================] - 35s 70ms/step - loss: 1.3941 - acc: 0.8925\n",
      "--------------------------------------------------------------------------\n",
      "Round: 0 Batch: 111\n",
      "--------------------------------------------------------------------------\n",
      "Getting data: 111000 1000\n",
      "(500, 20, 10000)\n",
      "Epoch 1/1\n",
      "500/500 [==============================] - 35s 70ms/step - loss: 1.3851 - acc: 0.8954\n",
      "--------------------------------------------------------------------------\n",
      "Round: 0 Batch: 112\n",
      "--------------------------------------------------------------------------\n",
      "Getting data: 112000 1000\n",
      "(500, 20, 10000)\n",
      "Epoch 1/1\n",
      "500/500 [==============================] - 35s 70ms/step - loss: 1.3743 - acc: 0.8973\n",
      "--------------------------------------------------------------------------\n",
      "Round: 0 Batch: 113\n",
      "--------------------------------------------------------------------------\n",
      "Getting data: 113000 1000\n",
      "(500, 20, 10000)\n",
      "Epoch 1/1\n",
      "500/500 [==============================] - 36s 72ms/step - loss: 1.3637 - acc: 0.8992\n",
      "--------------------------------------------------------------------------\n",
      "Round: 0 Batch: 114\n",
      "--------------------------------------------------------------------------\n",
      "Getting data: 114000 1000\n",
      "(500, 20, 10000)\n",
      "Epoch 1/1\n",
      "500/500 [==============================] - 38s 76ms/step - loss: 1.3602 - acc: 0.8990\n",
      "--------------------------------------------------------------------------\n",
      "Round: 0 Batch: 115\n",
      "--------------------------------------------------------------------------\n",
      "Getting data: 115000 1000\n",
      "(500, 20, 10000)\n",
      "Epoch 1/1\n",
      "500/500 [==============================] - 38s 76ms/step - loss: 1.3567 - acc: 0.8998\n",
      "--------------------------------------------------------------------------\n",
      "Round: 0 Batch: 116\n",
      "--------------------------------------------------------------------------\n",
      "Getting data: 116000 1000\n",
      "(500, 20, 10000)\n",
      "Epoch 1/1\n",
      "500/500 [==============================] - 36s 73ms/step - loss: 1.3546 - acc: 0.8997\n",
      "--------------------------------------------------------------------------\n",
      "Round: 0 Batch: 117\n",
      "--------------------------------------------------------------------------\n",
      "Getting data: 117000 1000\n",
      "(500, 20, 10000)\n",
      "Epoch 1/1\n",
      "500/500 [==============================] - 35s 69ms/step - loss: 1.3545 - acc: 0.9007\n",
      "--------------------------------------------------------------------------\n",
      "Round: 0 Batch: 118\n",
      "--------------------------------------------------------------------------\n",
      "Getting data: 118000 1000\n",
      "(500, 20, 10000)\n",
      "Epoch 1/1\n",
      "500/500 [==============================] - 39s 77ms/step - loss: 1.3586 - acc: 0.8993\n",
      "--------------------------------------------------------------------------\n",
      "Round: 0 Batch: 119\n",
      "--------------------------------------------------------------------------\n",
      "Getting data: 119000 1000\n",
      "(500, 20, 10000)\n",
      "Epoch 1/1\n",
      "500/500 [==============================] - 40s 79ms/step - loss: 1.3594 - acc: 0.8981\n",
      "--------------------------------------------------------------------------\n",
      "Round: 0 Batch: 120\n",
      "--------------------------------------------------------------------------\n",
      "Getting data: 120000 1000\n",
      "(500, 20, 10000)\n",
      "Epoch 1/1\n",
      "500/500 [==============================] - 39s 77ms/step - loss: 1.3589 - acc: 0.8958\n",
      "--------------------------------------------------------------------------\n",
      "Round: 0 Batch: 121\n",
      "--------------------------------------------------------------------------\n",
      "Getting data: 121000 1000\n",
      "(500, 20, 10000)\n",
      "Epoch 1/1\n",
      "500/500 [==============================] - 38s 76ms/step - loss: 1.3512 - acc: 0.9008\n",
      "--------------------------------------------------------------------------\n",
      "Round: 0 Batch: 122\n",
      "--------------------------------------------------------------------------\n",
      "Getting data: 122000 1000\n",
      "(500, 20, 10000)\n",
      "Epoch 1/1\n",
      "500/500 [==============================] - 35s 70ms/step - loss: 1.3472 - acc: 0.9009\n",
      "--------------------------------------------------------------------------\n",
      "Round: 0 Batch: 123\n",
      "--------------------------------------------------------------------------\n",
      "Getting data: 123000 1000\n",
      "(500, 20, 10000)\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-24-535272eab50d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     11\u001b[0m         \u001b[0mx_vec\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_vec\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mload_twitter_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstart_point\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvocab_dict\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m         \u001b[0mround\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 13\u001b[1;33m     \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_vec\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_vec\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m200\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnb_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m \u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     14\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msave_weights\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m%\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;34m\"new_chatbot_model.h5\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m     \u001b[0mstart_point\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\models.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[0;32m   1000\u001b[0m                               \u001b[0minitial_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1001\u001b[0m                               \u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1002\u001b[1;33m                               validation_steps=validation_steps)\n\u001b[0m\u001b[0;32m   1003\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1004\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[0;32m   1703\u001b[0m                               \u001b[0minitial_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1704\u001b[0m                               \u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1705\u001b[1;33m                               validation_steps=validation_steps)\n\u001b[0m\u001b[0;32m   1706\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1707\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36m_fit_loop\u001b[1;34m(self, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[0;32m   1234\u001b[0m                         \u001b[0mins_batch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1235\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1236\u001b[1;33m                     \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1237\u001b[0m                     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1238\u001b[0m                         \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mouts\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   2480\u001b[0m         \u001b[0msession\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_session\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2481\u001b[0m         updated = session.run(fetches=fetches, feed_dict=feed_dict,\n\u001b[1;32m-> 2482\u001b[1;33m                               **self.session_kwargs)\n\u001b[0m\u001b[0;32m   2483\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mupdated\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2484\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    898\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    899\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[1;32m--> 900\u001b[1;33m                          run_metadata_ptr)\n\u001b[0m\u001b[0;32m    901\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    902\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run\u001b[1;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1133\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1134\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[1;32m-> 1135\u001b[1;33m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[0;32m   1136\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1137\u001b[0m       \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_run\u001b[1;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1314\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1315\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[1;32m-> 1316\u001b[1;33m                            run_metadata)\n\u001b[0m\u001b[0;32m   1317\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1318\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m   1320\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1321\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1322\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1323\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1324\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[1;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[0;32m   1305\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_extend_graph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1306\u001b[0m       return self._call_tf_sessionrun(\n\u001b[1;32m-> 1307\u001b[1;33m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[0;32m   1308\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1309\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[1;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[0;32m   1407\u001b[0m       return tf_session.TF_SessionRun_wrapper(\n\u001b[0;32m   1408\u001b[0m           \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1409\u001b[1;33m           run_metadata)\n\u001b[0m\u001b[0;32m   1410\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1411\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mraise_exception_on_not_ok_status\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mstatus\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "batch_size = 1000\n",
    "start_point = 0\n",
    "batch = 0\n",
    "round = 0\n",
    "while True:\n",
    "    print(\"Getting data:\", start_point, batch_size)\n",
    "    x_vec, y_vec = load_twitter_data(start_point, batch_size, vocab_dict)\n",
    "    if len(x_vec) == 0:\n",
    "        start_point = 0\n",
    "        batch = 0\n",
    "        x_vec, y_vec = load_twitter_data(start_point, batch_size, vocab_dict)\n",
    "        round += 1\n",
    "    model.fit(x_vec, y_vec, batch_size=200, nb_epoch=1 )\n",
    "    model.save_weights(str(batch%2)+\"new_chatbot_model.h5\")\n",
    "    start_point += batch_size\n",
    "    batch += 1\n",
    "    print(\"--------------------------------------------------------------------------\")\n",
    "    print(\"Round:\", round, \"Batch:\", batch)\n",
    "    print(\"--------------------------------------------------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"                            you you   can't head UNK\""
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sen = \"pretty\"\n",
    "sen = sen.lower().replace('?', '').replace('!', '').replace( '.', '')\n",
    "vec = sentence_to_vec([sen], vocab_dict, 'UNK', SENTENCE_LENGTH)\n",
    "#print(model.predict(vec).shape)\n",
    "res = model.predict(vec)\n",
    "\n",
    "vec_y = np.argmax(res, axis=2)\n",
    "\" \".join([idx_dict[x] for x in vec_y[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"                            think i'm is is week week\""
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sen = \"hi\"\n",
    "sen = sen.lower().replace('?', '').replace('!', '').replace( '.', '')\n",
    "vec = sentence_to_vec([sen], vocab_dict, 'UNK', SENTENCE_LENGTH)\n",
    "#print(model.predict(vec).shape)\n",
    "res = model.predict(vec)\n",
    "\n",
    "vec_y = np.argmax(res, axis=2)\n",
    "\" \".join([idx_dict[x] for x in vec_y[0] if idx_dict[x]!= 'UNK'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
